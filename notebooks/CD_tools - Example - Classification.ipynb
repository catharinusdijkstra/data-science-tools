{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter # import warnings filter\n",
    "simplefilter(action='ignore', category=FutureWarning) # ignore all future warnings\n",
    "\n",
    "from cdtools.util.pandas_dataframe_operations import compare_dataframes, impute_dataframe\n",
    "from cdtools.CD_tools import CDML, compare_binary_columns, df_2_xlsx, df_balance, high_correlation_filter, PCA_analyse, voting_classifier, zero_variance_columns\n",
    "from cdtools.dataprocessing.feature_engineering import get_feature_lists\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show figures inside the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Show all columns inside the dataframe\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Set default figure size of figures in the notebook\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "\n",
    "# Set fonts\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_directory = \"../data/input/titanic/\"\n",
    "output_data_directory = \"../data/output/titanic/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data_types = {\n",
    "    \"PassengerId\": str, # Passenger identifier.\n",
    "    #\"Name\": str, # Passenger name.\n",
    "    \"Sex\": str, # Gender.\n",
    "    \"Age\": float, # Age in years.\n",
    "    \"SibSp\": int, # Number of siblings / spouses aboard the Titanic.\n",
    "    \"Parch\": int, # Number of parents / children aboard the Titanic.\n",
    "    \"Embarked\": str, # Port of embarkation.\n",
    "    #\"Ticket\": str, # Ticket number.\n",
    "    \"Pclass\": str, # Ticket class.\n",
    "    #\"Cabin\": str, # Cabin number.    \n",
    "    \"Fare\": float, # Passenger fare.\n",
    "    \"Survived\": bool, # Survival indicator.\n",
    "    }\n",
    "\n",
    "keys = [\"PassengerId\"]\n",
    "labels = [\"Survived\"]\n",
    "features, features_categorical, features_numeric, features_boolean = (\n",
    "    get_feature_lists(column_data_types,keys,labels)\n",
    "    )\n",
    "features_categorical_classes_2_drop = [\"male\",\"S\",\"3\"]\n",
    "\n",
    "df_train_data = pd.read_csv(input_data_directory+\"train.csv\",dtype=column_data_types)\n",
    "df_train_data = df_train_data[keys + features + labels]\n",
    "df_test_data = pd.read_csv(input_data_directory+\"test.csv\",dtype=column_data_types)\n",
    "df_test_data = df_test_data[keys + features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing values per column before imputation.\")\n",
    "display(df_train_data.isnull().sum())\n",
    "df_train_data = impute_dataframe(df_train_data)\n",
    "print(\"Number of missing values per column after imputation.\")\n",
    "display(df_train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing values per column before imputation.\")\n",
    "display(df_test_data.isnull().sum())\n",
    "df_test_data = impute_dataframe(df_test_data)\n",
    "print(\"Number of missing values per column after imputation.\")\n",
    "display(df_test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a classification model with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = CDML(df_train_data,column_data_types,keys,labels,features_categorical_classes_2_drop=features_categorical_classes_2_drop)\n",
    "rc.split_data(test_size=0.1,random_state=0,sampling=None)\n",
    "rc.classification_model_data(\"RandomForestClassifier(random_state=0,n_estimators=100)\",threshold=0.5)\n",
    "rc.show_learning_curve(ylim=(0,1.1),cv=StratifiedKFold(12),n_jobs=4,train_sizes=np.linspace(0.3,1.0,10),scoring='roc_auc')\n",
    "rc.classification_show_ROC_precision_recall_curves(show_labels='Y',label_interval=6,label_offsets_ROC=[15,-20],label_offsets_PR=[-30,-30])\n",
    "rc.classification_show_prediction_distributions(nrbins=51)\n",
    "rc.save_feature_importance()\n",
    "rc.classification_show_interpretation_table(sort_columns='Y',top=5)\n",
    "rc.classification_transpose_interpretation_table()\n",
    "rc.classification_show_interpretation_table_LIME(top=5,num_samples=5000)\n",
    "rc.classification_transpose_interpretation_table_LIME()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the classification model using hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameter search grid\n",
    "random_grid = {'n_estimators': [10,50,100,150,200,250,500],\n",
    "               'criterion': ['gini','entropy','log_loss'],\n",
    "               'max_depth': [5,10,None],\n",
    "               'min_samples_split': [2,10,50,100,500],\n",
    "               'min_samples_leaf': [1,10,50,100,500],\n",
    "               'min_weight_fraction_leaf': [0.0],\n",
    "               'max_features': ['sqrt', 'log2', None],\n",
    "               'max_leaf_nodes': [None],\n",
    "               'min_impurity_decrease': [0.0],\n",
    "               'bootstrap': [True],\n",
    "               'oob_score': [False],\n",
    "               'n_jobs': [-1],\n",
    "               'random_state': [0],\n",
    "               'verbose': [0],\n",
    "               'warm_start': [False],\n",
    "               'class_weight': [None],\n",
    "               'ccp_alpha': [0.0],\n",
    "               'max_samples': [None]\n",
    "              }\n",
    "\n",
    "# Search the hyperparameter grid for the optimal hyperparameters\n",
    "rc = CDML(df_train_data,column_data_types,keys,labels,features_categorical_classes_2_drop=features_categorical_classes_2_drop)\n",
    "rc.split_data(test_size=0.1,random_state=0,sampling=None)\n",
    "rc.classification_model_data(\"RandomForestClassifier(random_state=0)\",threshold=0.5) # Run a model with default settings\n",
    "rc.RandomizedSearchCV(random_grid,n_iter=100)\n",
    "best_estimator = rc.model.randomized_search_CV.random_search.best_estimator_\n",
    "print(\"Best estimator:\")\n",
    "print(best_estimator)\n",
    "print()\n",
    "# Run the model with the optimal hyperparameters\n",
    "rc.classification_model_data(str(best_estimator),threshold=0.5) # Run the model with the optimal hyperparameters\n",
    "rc.show_learning_curve(ylim=(0,1.1),cv=StratifiedKFold(12),n_jobs=4,train_sizes=np.linspace(0.3,1.0,10),scoring='roc_auc')\n",
    "rc.classification_show_ROC_precision_recall_curves(show_labels='Y',label_interval=6,label_offsets_ROC=[15,-20],label_offsets_PR=[-30,-30])\n",
    "rc.classification_show_prediction_distributions(nrbins=51)\n",
    "rc.save_feature_importance()\n",
    "rc.classification_show_interpretation_table(sort_columns='Y',top=5)\n",
    "rc.classification_transpose_interpretation_table()\n",
    "rc.classification_show_interpretation_table_LIME(top=5,num_samples=5000)\n",
    "rc.classification_transpose_interpretation_table_LIME()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "66de807606c55c2731465052ec34737a0ab987fd86386beb29c4066fe5154c06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
